# ğŸš€ **CI/CD Pipeline â€” MLOps Iris Classifier**

This stage introduces **Continuous Integration and Continuous Deployment (CI/CD)** for the **MLOps Iris Classifier** using **GitLab Pipelines** and **Google Cloud Platform (GCP)**.
It automates the build, containerisation, and deployment of your Flask application into **Google Kubernetes Engine (GKE)**, enabling you to push updates directly from GitLab to production with minimal manual effort.

## ğŸ§© **Overview**

In this part of the project, you will:

1. Configure authentication with Google Cloud using a service account key.
2. Add the required files for containerisation and deployment (`Dockerfile`, `kubernetes-deployment.yaml`, `.gitlab-ci.yml`).
3. Encode your service account key into base64 for use in GitLab CI/CD variables.
4. Push to GitLab to trigger an automated build â†’ push â†’ deploy pipeline.
5. Access your running Flask application via the public endpoint in GKE.

## 1ï¸âƒ£ Copy and Rename Your Service Account Key

Locate the **JSON key** you previously downloaded from GCP (in your **Downloads** folder).
Copy it into your projectâ€™s **root directory** and rename it:

```bash
mv ~/Downloads/<your-key>.json gcp-key.json
```

This file will be used by your CI/CD pipeline to authenticate with Google Cloud services.

## 2ï¸âƒ£ Add the Dockerfile and Kubernetes Manifest

Copy the **`Dockerfile`** and **`kubernetes-deployment.yaml`** files from the reference repository into your project root.
You will also find the `.gitlab-ci.yml` in the same location.

In the **Kubernetes YAML file**, locate **line 26** (the image path).
Go to your **Artifact Registry** in GCP, click your repository, and select **â€œCopy pathâ€** on the right-hand side.

<p align="center">
  <img src="img/cicd/image_path.png" alt="Artifact Registry Image Path" style="width:100%; height:auto;"/>
</p>

Now paste this path into line 26 of the YAML file, then append `/<Your Image Name>:latest`.
For example:

```
us-central1-docker.pkg.dev/sacred-garden-474511-b9/mlops-iris-ii/mlops-iris-ii:latest
```

This ensures your Kubernetes deployment pulls the correct container image from GCP.

## 3ï¸âƒ£ Convert the GCP Key to Base64

Next, convert your JSON key to base64 format.
Open a terminal in your project root and run:

```bash
cat gcp-key.json | base64 -w 0
```

This command outputs your **base64-encoded key** as a single string.
It should look something like:

```
ewogICJ0eXB...29tIgp9Cg==
```

Copy the entire output â€” youâ€™ll use it when configuring your GitLab variable.

## 4ï¸âƒ£ Add the Base64 Key to GitLab CI/CD Variables

Log in to **GitLab**, open your project, and from the left-hand menu select **Settings â†’ CI/CD**.

<p align="center">
  <img src="img/cicd/gitlab_settings_cicd.png" alt="GitLab CI/CD Settings" style="width:100%; height:auto;"/>
</p>

Scroll down to the **Variables** section and click **â€œAdd variable.â€**

<p align="center">
  <img src="img/cicd/add_variable.png" alt="Add Variable Button" style="width:100%; height:auto;"/>
</p>

In the **Key** field, enter `GCP_SA_KEY`.
In the **Value** field, paste the base64-encoded key you generated earlier.
Set **Visibility** to *Visible*, then click **Add variable**.

<p align="center">
  <img src="img/cicd/key_added.png" alt="Key Added Successfully" style="width:100%; height:auto;"/>
</p>

This securely stores your credentials, allowing GitLab CI/CD to authenticate with GCP during pipeline execution.

## 5ï¸âƒ£ Add the `.gitlab-ci.yml` File

In your project root, create a file called `.gitlab-ci.yml` and paste the CI/CD pipeline configuration.
This file defines three stages â€” **checkout**, **build**, and **deploy** â€” and automates the entire workflow from code to production.

Once youâ€™ve added it, commit and push your code to GitLab:

```bash
git add .
git commit -m "Add CI/CD pipeline configuration"
git push gitlab main
```

This triggers your first CI/CD pipeline.

<p align="center">
  <img src="img/cicd/gitlab_job_running.png" alt="GitLab Job Running" style="width:100%; height:auto;"/>
</p>

After a few minutes, if all stages complete successfully, you will see:

<p align="center">
  <img src="img/cicd/pipeline_succeeded.png" alt="Pipeline Succeeded" style="width:100%; height:auto;"/>
</p>

## 6ï¸âƒ£ Verify the Deployment in GCP

Return to the **Google Cloud Console**.
Navigate to **Kubernetes Engine â†’ Workloads**.

<p align="center">
  <img src="img/cicd/gcp_workloads.png" alt="GCP Workloads" style="width:100%; height:auto;"/>
</p>

Click on **mlops-iris-ii** and scroll down to the **Exposing services** section.

<p align="center">
  <img src="img/cicd/endpoint.png" alt="Kubernetes Service Endpoint" style="width:100%; height:auto;"/>
</p>

The **Endpoint** link is your live project endpoint.
Click it to open the deployed **MLOps Iris Classifier** web application in your browser.

<p align="center">
  <img src="img/flask/flask_app.png" alt="Flask App Running on GKE" style="width:100%; height:auto;"/>
</p>

You can now interact with the classifier directly from your deployed GCP environment â€” entering input values and receiving predictions in real time.

## ğŸ—‚ï¸ **Updated Project Structure**

```text
mlops_iris_classifier/
â”œâ”€â”€ .venv/                          # ğŸ§© Local virtual environment (created by uv)
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ data.csv                # ğŸŒ¸ Input Iris dataset
â”‚   â”œâ”€â”€ processed/                  # ğŸ’¾ Preprocessed artefacts (from DataProcessing)
â”‚   â”‚   â”œâ”€â”€ X_train.pkl
â”‚   â”‚   â”œâ”€â”€ X_test.pkl
â”‚   â”‚   â”œâ”€â”€ y_train.pkl
â”‚   â”‚   â””â”€â”€ y_test.pkl
â”‚   â””â”€â”€ models/                     # ğŸ§  Trained model and evaluation artefacts
â”‚       â”œâ”€â”€ model.pkl
â”‚       â””â”€â”€ confusion_matrix.png
â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ cicd/
â”‚   â””â”€â”€ flask/
â”œâ”€â”€ mlops_iris_classifier.egg-info/ # ğŸ“¦ Package metadata (auto-generated)
â”œâ”€â”€ pipeline/                       # âš™ï¸ Workflow orchestration layer
â”‚   â””â”€â”€ training_pipeline.py        # Executes data preparation + model training
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py         # Unified and detailed exception handling
â”‚   â”œâ”€â”€ logger.py                   # Centralised logging configuration
â”‚   â”œâ”€â”€ data_processing.py          # ğŸŒ± Data preparation workflow
â”‚   â””â”€â”€ model_training.py           # ğŸŒ³ Model training and evaluation workflow
â”œâ”€â”€ static/                         # ğŸ¨ Visual assets (used in Flask UI)
â”œâ”€â”€ templates/                      # ğŸ§© Flask HTML templates (for app stage)
â”œâ”€â”€ .gitignore                      # ğŸš« Git ignore rules
â”œâ”€â”€ .python-version                 # ğŸ Python version pin
â”œâ”€â”€ pyproject.toml                  # âš™ï¸ Project metadata and uv configuration
â”œâ”€â”€ requirements.txt                # ğŸ“¦ Python dependencies
â”œâ”€â”€ setup.py                        # ğŸ”§ Editable install support
â”œâ”€â”€ uv.lock                         # ğŸ”’ Locked dependency versions
â”œâ”€â”€ Dockerfile                      # ğŸ³ Container image definition
â”œâ”€â”€ kubernetes-deployment.yaml      # â˜¸ï¸ Deployment & Service configuration
â””â”€â”€ .gitlab-ci.yml                  # ğŸš€ CI/CD pipeline configuration for GitLab
```

## âœ… **In Summary**

This stage transforms the **MLOps Iris Classifier** into a fully automated, production-ready system.
Every code push triggers a pipeline that builds the Docker image, pushes it to **GCP Artifact Registry**, updates the **Kubernetes cluster**, and deploys the live application automatically.

By combining **GitLab CI/CD** with **Google Cloud Platform**, you now have a complete end-to-end MLOps workflow â€” from data ingestion and model training to deployment and live inference.
